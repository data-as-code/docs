{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Data as Code","text":"<p>Data as Code (DaC) is a paradigm of distributing versioned data as code. Think of it as treating your data with the same care and precision as your software.</p> <p>Disclaimer</p> <p>At the moment, we're focusing on tabular and batch data, with Python as the primary language.</p> <p>But who knows? With enough community interest, we might expand to other areas in the future!</p>"},{"location":"#consumer-data-scientist","title":"Consumer - Data Scientist","text":"Follow along <p>Want to try the examples below on your own machine? It's easy! Just configure <code>pip</code> to point to the PyPI registry where the example DaC package is stored. Run this command:</p> <pre><code>\u276f export PIP_EXTRA_INDEX_URL=https://gitlab.com/api/v4/projects/43746775/packages/pypi/simple\n</code></pre> <p>And don't forget to create an isolated environment before installing the package:</p> <pre><code>\u276f python -m venv venv &amp;&amp; . venv/bin/activate\n</code></pre> <p>Imagine the Data Engineers have prepared a DaC package called <code>dac-example-energy</code> just for you. Install it like this:</p> <pre><code>\u276f python -m pip install dac-example-energy\n...\nSuccessfully installed ... dac-example-energy-2.0.2 ...\n</code></pre> <p>Notice the version <code>2.0.2</code>? That\u2019s the version of your data! Curious to know more about the importance of the version? Check out this section.</p>"},{"location":"#grab-the-data-with-the-snap-of-a-finger-load","title":"Grab the data with the snap of a finger: <code>load</code>","text":"<p>Now, let\u2019s grab the data:</p> <pre><code>&gt;&gt;&gt; from dac_example_energy import load\n&gt;&gt;&gt; df = load()\n&gt;&gt;&gt; df\n                         nrg_bal_name            siec_name geo  TIME_PERIOD  OBS_VALUE\n0      Final consumption - energy use   Solid fossil fuels  AL         1990   6644.088\n1      Final consumption - energy use   Solid fossil fuels  AL         1991   3816.945\n2      Final consumption - energy use   Solid fossil fuels  AL         1992   1067.475\n3      Final consumption - energy use   Solid fossil fuels  AL         1993    525.540\n4      Final consumption - energy use   Solid fossil fuels  AL         1994    459.514\n...                               ...                  ...  ..          ...        ...\n71155          Gross available energy  Non-renewable waste  XK         2015      0.000\n71156          Gross available energy  Non-renewable waste  XK         2016      0.000\n71157          Gross available energy  Non-renewable waste  XK         2017      0.000\n71158          Gross available energy  Non-renewable waste  XK         2018      0.000\n71159          Gross available energy  Non-renewable waste  XK         2019      0.000\n\n[71160 rows x 5 columns]\n</code></pre>"},{"location":"#meet-the-schema-class-your-datas-best-friend","title":"Meet the <code>Schema</code> Class: Your Data\u2019s Best Friend","text":"<p>The <code>Schema</code> class is the backbone of the Data Contract. It\u2019s a promise between the data producer and the data consumer. It defines the structure, constraints, and expectations for the data. And here\u2019s the best part: any data you load is guaranteed to pass validation.</p> <p>Let\u2019s explore what the <code>Schema</code> in the <code>dac-example-energy</code> package can do:</p> <pre><code>&gt;&gt;&gt; from dac_example_energy import Schema\n&gt;&gt;&gt; import inspect\n&gt;&gt;&gt; print(inspect.getsource(Schema))\nclass Schema(pa.SchemaModel):\n    source: Series[str] = pa.Field(\n        isin=[\n            \"Solid fossil fuels\",\n            ...\n            \"Non-renewable waste\",\n        ],\n        nullable=False,\n        alias=\"siec_name\",\n        description=\"Source of energy\",\n    )\n    value_meaning: Series[str] = pa.Field(\n        isin=[\n            \"Gross available energy\",\n            ...\n            \"Final consumption - transport sector - energy use\",\n        ],\n        nullable=False,\n        alias=\"nrg_bal_name\",\n        description=\"Meaning of the value\",\n    )\n    location: Series[str] = pa.Field(\n        isin=[\n            \"AL\",\n            ...\n            \"XK\",\n        ],\n        nullable=False,\n        alias=\"geo\",\n        description=\"Location code, either two-digit ISO 3166-1 alpha-2 code or \"\n        \"'EA19', 'EU27_2020', 'EU28' for the European Union\",\n    )\n    year: Series[int] = pa.Field(\n        ge=1990,\n        le=3000,\n        nullable=False,\n        alias=\"TIME_PERIOD\",\n        description=\"Year of observation\",\n    )\n    value_in_gwh: Series[float] = pa.Field(\n        nullable=True,\n        alias=\"OBS_VALUE\",\n        description=\"Value in GWh\",\n    )\n</code></pre> <p>This <code>Schema</code> is built using <code>pandera</code>. Here\u2019s why it\u2019s awesome:</p> <ul> <li>Column names are accessible: No more hardcoding strings! Reference column names directly in your code:     <pre><code>&gt;&gt;&gt; df[Schema.value_in_gwh]\n0        6644.088\n1        3816.945\n2        1067.475\n3         525.540\n4         459.514\n           ...\n71155       0.000\n71156       0.000\n71157       0.000\n71158       0.000\n71159       0.000\nName: OBS_VALUE, Length: 71160, dtype: float64\n</code></pre></li> <li>Clear expectations: Know exactly what each column should contain\u2014types, constraints, and more.</li> <li>Self-documenting: Each column comes with a description.</li> <li>Synthetic data generation: Install <code>pandera[strategies]</code> and generate test data that passes validation:     <pre><code>&gt;&gt;&gt; Schema.example(size=5)\n            siec_name            nrg_bal_name geo  TIME_PERIOD  OBS_VALUE\n0         Natural gas  Gross available energy  AL         1990        0.0\n1  Solid fossil fuels  Gross available energy  AL         1990        0.0\n2  Solid fossil fuels  Gross available energy  AL         1990        0.0\n3  Solid fossil fuels  Gross available energy  AL         1990        0.0\n4  Solid fossil fuels  Gross available energy  AL         1990        0.0\n</code></pre></li> </ul> <p>Example data looks odd?</p> <p>The synthetic data above might not look realistic. Does this mean the <code>example</code> method is broken? Not at all! Check out this section to learn more.</p>"},{"location":"#producer-data-engineer","title":"Producer - Data Engineer","text":"<p>Data as Code is a paradigm, not a tool. You can implement it however you like, in any language. That said, we\u2019ve built some handy tools to make your life easier.</p> <p>Pro Tip: Use <code>pandera</code> for defining schemas</p> <p>If your dataframe engine (pandas, polars, dask, spark, etc.) is supported by <code>pandera</code>, consider using a <code>DataFrameModel</code> to define your schema.</p>"},{"location":"#write-the-library","title":"Write the library","text":""},{"location":"#1-start-from-scratch","title":"1. Start from scratch","text":"<p>This approach requires Python packaging knowledge</p> <p>Build your own library while following these guidelines:</p>"},{"location":"#public-function-load","title":"Public function <code>load</code>","text":"<p>Your package must have a public function named <code>load</code> at its root. For example, if your package is <code>dac-my-awesome-data</code>, users should be able to do this:</p> <pre><code>&gt;&gt;&gt; from dac_my_awesome_data import load\n&gt;&gt;&gt; df = load()\n</code></pre> <p>The <code>load()</code> function should return data corresponding to the package version. Each build should produce different data.</p>"},{"location":"#data-must-pass-schemavalidate","title":"Data must pass <code>Schema.validate()</code>","text":"<p>A public class named <code>Schema</code> is available at the root of package and implements the Data Contract. <code>Schema</code> has a <code>validate</code> method which takes data as input and raises an error if the Contract is not fulfilled, and returns the data otherwise.</p> <p>Notice that the Data Contract should be verified at building time, therefore ensuring that given a Data as Code package, the data coming from <code>load()</code> will always fulfill the Data Contract.</p> <p>This means that, for example, it must be possible to do the following:</p> <pre><code>&gt;&gt;&gt; from dac_my_awesome_data import load, Schema\n&gt;&gt;&gt; Schema.validate(load())\n</code></pre> <p>and will never raise an error.</p>"},{"location":"#nice-to-have-schema-contains-column-names","title":"[Nice to have] <code>Schema</code> contains column names","text":"<p>It is possible to reference the column names from the <code>Schema</code> class. For example:</p> <pre><code>&gt;&gt;&gt; from dac_my_awesome_data import load, Schema\n&gt;&gt;&gt; df = load()\n&gt;&gt;&gt; df[Schema.column_1]\n</code></pre>"},{"location":"#nice-to-have-schemaexample-method","title":"[Nice to have] <code>Schema.example</code> method","text":"<p>Provide a method to generate synthetic data that fulfills the Data Contract:</p> <pre><code>&gt;&gt;&gt; from dac_my_awesome_data import Schema\n&gt;&gt;&gt; Schema.example(size=5)\n   column_1  column_2\n0         1         2\n1         3         4\n2         5         6\n3         7         8\n4         9        10\n</code></pre> <p>Ideally synthetic data should be such to really stretch the limits of the Data Contract. By this we mean that the generated data should be as far aways as possible to the real data, but still fulfill the Data Contract. This is useful to make the tests built using this feature as robust as possible. Also, this will push the developers to improve the Data Contract, and therefore will make it as reliable as possible. For example, in the Consumer section, you may have noticed that the rows have nearly alwyas the same values. This is unlikely to be the case in the real data, but as it is not envoded in the Schema it may still happen! It would be probably a good idea to add meaningful constraint checks to the <code>Schema</code> class.</p>"},{"location":"#2-use-the-template","title":"2. Use the template","text":"<p>We\u2019ve created a Copier template to help you get started quickly.</p> <p>Check out the template </p>"},{"location":"#3-use-the-dac-cli-tool","title":"3. Use the <code>dac</code> CLI tool","text":"<p>Our <code>dac</code> CLI tool simplifies building Python packages that follow the Data as Code paradigm.</p> <p>Explore the <code>dac</code> CLI tool </p>"},{"location":"#template-vs-dac-pack","title":"Template vs. <code>dac pack</code>","text":"<p>Which one should you choose?</p> Template <code>dac pack</code> Simplicity Possibility of customization"},{"location":"#make-releases","title":"Make Releases","text":"<p>Choosing the right release version plays a crucial role in the Data as Code paradigm.</p> When to Use Patch Fixes in the data without changing its intended content Minor Non-breaking changes, like a fresh version of the batch data Major Breaking changes, such as changes to the Data Contract <p>Patch and Major releases are usually manual, while Minor releases can be automated. Use the <code>dac</code> CLI tool to automate Minor releases with the <code>dac next-version</code> command.</p>"},{"location":"#why-distributing-data-as-code","title":"Why distributing Data as Code?","text":"<ul> <li>Seamless compatibility: Data Scientists can ensure their code runs on compatible data by including the Data as     Code package as a dependency to their code. For example, if they add <code>dac-example-energy~=1.0</code> to the dependencies,     it will not be possible to use it together with <code>dac-example-energy==2.0.0</code>.</li> <li>Smooth updates: Data pipelines can receive updates without breaking, as long as they subscribe to a major version.</li> <li>Multiple release streams: Maintain different versions (e.g., <code>1.X.Y</code> and <code>2.X.Y</code>) to support users on older     versions.</li> <li>Abstracted complexity: Data loading, sources, and locations are hidden from consumers, allowing producers to     change implementations without impacting users.</li> <li>No hardcoded column names: If column names are included in the <code>Schema</code>, consumers can avoid hardcoding field     names.</li> <li>Robust testing: If the <code>Schema.example</code> method is provided, it enables consumers to write strong unit tests for     their code.</li> <li>Self-documenting data: If data and column descriptions are included in the <code>Schema</code>, data will be easier to     understand for consumers.</li> </ul>"}]}